{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../dataset_nyc_taxi_samples/parquet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_dict(names: List[str], csv_root: str) -> Dict[str, pd.DataFrame]:\n",
    "    csv_dict = {}\n",
    "\n",
    "    for name in names:\n",
    "        csv_dict[name] = {}\n",
    "        csv_dict[name][\"train\"] = pd.read_csv(os.path.join(csv_root, f\"{name}_train_1M.csv\"))\n",
    "\n",
    "        csv_dict[name][\"valid\"] = pd.read_csv(os.path.join(csv_root, f\"{name}_valid_500k.csv\"))\n",
    "    \n",
    "    return csv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20085/649362036.py:6: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_dict[name][\"train\"] = pd.read_csv(os.path.join(csv_root, f\"{name}_train_1M.csv\"))\n",
      "/tmp/ipykernel_20085/649362036.py:8: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv_dict[name][\"valid\"] = pd.read_csv(os.path.join(csv_root, f\"{name}_valid_500k.csv\"))\n"
     ]
    }
   ],
   "source": [
    "names = [\"fhv\", \"green\", \"yellow\"]\n",
    "\n",
    "csv_dict = get_csv_dict(names, \"../dataset_nyc_taxi_samples/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_columns(df: pd.DataFrame, taxi_type: str) -> pd.DataFrame:\n",
    "\n",
    "    if taxi_type == \"green\":\n",
    "        df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "        df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "\n",
    "        df['store_and_fwd_flag'] = df['store_and_fwd_flag'] == 'Y'\n",
    "        df['store_and_fwd_flag'] = df['store_and_fwd_flag'].astype(int)\n",
    "\n",
    "        df['trip_time'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
    "        df['trip_time'] = df['trip_time'].values.astype(float)//10**9\n",
    "\n",
    "        df['month'] = df['lpep_pickup_datetime'].dt.month\n",
    "        df['weekday'] = df['lpep_pickup_datetime'].dt.weekday\n",
    "        df['hour'] = df['lpep_pickup_datetime'].dt.hour\n",
    "\n",
    "        df = df.drop(columns=['lpep_pickup_datetime', 'lpep_dropoff_datetime', 'ehail_fee', 'total_amount'])\n",
    "\n",
    "\n",
    "    if taxi_type == \"yellow\":\n",
    "        df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "        df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "        df['store_and_fwd_flag'] = df['store_and_fwd_flag'] == 'Y'\n",
    "        df['store_and_fwd_flag'] = df['store_and_fwd_flag'].astype(int)\n",
    "\n",
    "        df['trip_time'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n",
    "        df['trip_time'] = df['trip_time'].values.astype(float)//10**9\n",
    "\n",
    "        df['month'] = df['tpep_pickup_datetime'].dt.month\n",
    "        df['weekday'] = df['tpep_pickup_datetime'].dt.weekday\n",
    "        df['hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "        df = df.drop(columns=['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'airport_fee', 'total_amount'])\n",
    "\n",
    "    if taxi_type == \"fhv\":\n",
    "        df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "        df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'])\n",
    "        df['request_datetime'] = pd.to_datetime(df['request_datetime'])\n",
    "\n",
    "        for flag in ['shared_request_flag', 'shared_match_flag', 'access_a_ride_flag', 'wav_request_flag', 'wav_match_flag']:\n",
    "            df[flag] = df[flag] == 'Y'\n",
    "            df[flag] = df[flag].astype(int)\n",
    "\n",
    "        df['trip_time'] = df['dropoff_datetime'] - df['pickup_datetime']\n",
    "        df['trip_time'] = df['trip_time'].values.astype(float)//10**9\n",
    "\n",
    "        df['wait_time'] = df['pickup_datetime'] - df['request_datetime']\n",
    "        df['wait_time'] = df['wait_time'].values.astype(float)//10**9\n",
    "\n",
    "        df['month'] = df['pickup_datetime'].dt.month\n",
    "        df['weekday'] = df['pickup_datetime'].dt.weekday\n",
    "        df['hour'] = df['pickup_datetime'].dt.hour\n",
    "\n",
    "        df = df.drop(columns=['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num', 'airport_fee',\n",
    "                                        'request_datetime', 'on_scene_datetime', 'pickup_datetime', 'dropoff_datetime',])\n",
    "    \n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = gpd.read_file(\"../taxi_zones\")\n",
    "location_to_borough_mapping = dict(zip(shapefile['LocationID'], shapefile['borough']))\n",
    "borough_to_borough_idx_mappng = {'Manhattan': 0, 'Queens': 1, 'Brooklyn': 2, 'Bronx': 3, 'EWR': 4, 'Staten Island': 5}\n",
    "\n",
    "location_to_borough_idx_mapping = dict(zip(shapefile['LocationID'], shapefile['borough'].map(borough_to_borough_idx_mappng)))\n",
    "shapefile['borough_id'] = shapefile['borough'].map(borough_to_borough_idx_mappng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhv - train reduced: 0.04675354286691461%, num samples: 46752\n",
      "fhv - valid reduced: 0.046842594722158334%, num samples: 23422\n",
      "green - train reduced: 0.009437283118493555%, num samples: 9437\n",
      "green - valid reduced: 0.00951161953521859%, num samples: 4756\n",
      "yellow - train reduced: 0.005849181324621063%, num samples: 5849\n",
      "yellow - valid reduced: 0.0057577927194620996%, num samples: 2879\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    # change id, map borough to id\n",
    "    csv_dict[name][\"train\"][\"PUBoroughID\"] = (csv_dict[name][\"train\"][\"PULocationID\"]-1).map(location_to_borough_idx_mapping)\n",
    "    csv_dict[name][\"train\"][\"DOBoroughID\"] = (csv_dict[name][\"train\"][\"DOLocationID\"]-1).map(location_to_borough_idx_mapping)\n",
    "    csv_dict[name][\"valid\"][\"PUBoroughID\"] = (csv_dict[name][\"valid\"][\"PULocationID\"]-1).map(location_to_borough_idx_mapping)\n",
    "    csv_dict[name][\"valid\"][\"DOBoroughID\"] = (csv_dict[name][\"valid\"][\"DOLocationID\"]-1).map(location_to_borough_idx_mapping)\n",
    "\n",
    "    # drop nans on PUBoroughID, DOBoroughID\n",
    "    len_train_before = len(csv_dict[name][\"train\"])\n",
    "    len_valid_before = len(csv_dict[name][\"valid\"])\n",
    "\n",
    "    csv_dict[name][\"train\"].dropna(subset=[\"PUBoroughID\", \"DOBoroughID\"], inplace=True)\n",
    "    csv_dict[name][\"valid\"].dropna(subset=[\"PUBoroughID\", \"DOBoroughID\"], inplace=True)\n",
    "\n",
    "    csv_dict[name][\"train\"] = update_columns(csv_dict[name][\"train\"], name)\n",
    "    csv_dict[name][\"valid\"] = update_columns(csv_dict[name][\"valid\"], name)\n",
    "\n",
    "    len_train_after = len(csv_dict[name][\"train\"])\n",
    "    len_valid_after = len(csv_dict[name][\"valid\"])\n",
    "\n",
    "    print(f\"{name} - train reduced: {(len_train_before-len_train_after)/len_train_before}%, num samples: {len_train_before-len_train_after}\")\n",
    "    print(f\"{name} - valid reduced: {(len_valid_before-len_valid_after)/len_valid_before}%, num samples: {len_valid_before-len_valid_after}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def train_per_dataset(\n",
    "    experiment_name: str,\n",
    "    csv_dict: Dict, \n",
    "    names: List[str], \n",
    "    transform_data: Callable, \n",
    "    fit_predict: Callable\n",
    "    ) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.DataFrame([])\n",
    "    for name in names:\n",
    "        scaler = MinMaxScaler()\n",
    "        tip_label = [label for label in csv_dict[name][\"train\"].columns if \"tip\" in label][0]\n",
    "\n",
    "        csv_dict_transformed = {}\n",
    "        csv_dict_transformed[name] = transform_data(csv_dict[name].copy(), name)\n",
    "        \n",
    "        y_train = csv_dict_transformed[name][\"train\"].copy()[tip_label].to_numpy()\n",
    "        y_val = csv_dict_transformed[name][\"valid\"].copy()[tip_label].to_numpy()\n",
    "\n",
    "        x_train = csv_dict_transformed[name][\"train\"].copy().drop(columns=[tip_label]).to_numpy()\n",
    "        x_val = csv_dict_transformed[name][\"valid\"].copy().drop(columns=[tip_label]).to_numpy()\n",
    "\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_val = scaler.transform(x_val)\n",
    "\n",
    "        y_pred = fit_predict(x_train, y_train, x_val)\n",
    "        \n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        print(f\"\"\"\n",
    "        ============================================================\n",
    "        Dataset: {name}\n",
    "\n",
    "        Train num: {len(y_train)}\n",
    "        Val num: {len(y_val)}\n",
    "        Train + Val num: {len(np.concatenate([y_train, y_val]))}\n",
    "\n",
    "        Train Mean tip: {np.mean(y_train)}\n",
    "        Val Mean tip: {np.mean(y_val)}\n",
    "        Train + Val Mean tip: {np.mean(np.concatenate([y_train, y_val]))}\n",
    "        \n",
    "        Mean Squared Error: {mse}\n",
    "        Mean Absolute Error: {mae}\n",
    "        ============================================================\n",
    "        \"\"\"\n",
    "        )\n",
    "        \n",
    "        row = pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"experiment_name\": [experiment_name],\n",
    "                \"name\": [name],\n",
    "                \"mse\": [mse],\n",
    "                \"mae\": [mae],\n",
    "            }\n",
    "            )\n",
    "        df = pd.concat([df, row])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'passenger_count', 'trip_distance', 'RatecodeID',\n",
       "       'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type',\n",
       "       'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
       "       'improvement_surcharge', 'congestion_surcharge', 'retail_price',\n",
       "       'temperature_2m (°C)', 'relative_humidity_2m (%)', 'dew_point_2m (°C)',\n",
       "       'apparent_temperature (°C)', 'precipitation (mm)', 'rain (mm)',\n",
       "       'snowfall (cm)', 'snow_depth (m)', 'surface_pressure (hPa)',\n",
       "       'cloud_cover (%)', 'wind_speed_10m (km/h)', 'is_day ()', 'PUBoroughID',\n",
       "       'DOBoroughID', 'trip_time', 'month', 'weekday', 'hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dict[name][\"train\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Data - Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ============================================================\n",
      "        Dataset: fhv\n",
      "\n",
      "        Train num: 953215\n",
      "        Val num: 476593\n",
      "        Train + Val num: 1429808\n",
      "\n",
      "        Train Mean tip: 0.762667058323673\n",
      "        Val Mean tip: 0.7605058823776264\n",
      "        Train + Val Mean tip: 0.7619466809529671\n",
      "        \n",
      "        Mean Squared Error: 4.634459390855498\n",
      "        Mean Absolute Error: 1.2076065665555733\n",
      "        ============================================================\n",
      "        \n",
      "\n",
      "        ============================================================\n",
      "        Dataset: green\n",
      "\n",
      "        Train num: 990533\n",
      "        Val num: 495264\n",
      "        Train + Val num: 1485797\n",
      "\n",
      "        Train Mean tip: 2.2083399139655118\n",
      "        Val Mean tip: 2.2135968089746076\n",
      "        Train + Val Mean tip: 2.210092206405047\n",
      "        \n",
      "        Mean Squared Error: 6.683244293988039\n",
      "        Mean Absolute Error: 1.3983482675412024\n",
      "        ============================================================\n",
      "        \n",
      "\n",
      "        ============================================================\n",
      "        Dataset: yellow\n",
      "\n",
      "        Train num: 994120\n",
      "        Val num: 497139\n",
      "        Train + Val num: 1491259\n",
      "\n",
      "        Train Mean tip: 3.308909900213255\n",
      "        Val Mean tip: 3.313971867023106\n",
      "        Train + Val Mean tip: 3.310597401256256\n",
      "        \n",
      "        Mean Squared Error: 3.9543684977364024\n",
      "        Mean Absolute Error: 0.9597584872731378\n",
      "        ============================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_predict(x_train, y_train, x_val):\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_val)\n",
    "    return y_pred\n",
    "\n",
    "def transform_data(csv_dict, name):\n",
    "    return csv_dict\n",
    "\n",
    "df = train_per_dataset(\n",
    "    experiment_name=\"all data - regression model\",\n",
    "    csv_dict=csv_dict, \n",
    "    names=names, \n",
    "    transform_data=transform_data, \n",
    "    fit_predict=fit_predict\n",
    "    )\n",
    "\n",
    "results = pd.concat([results, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Data - Experiment models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def fit_predict(x_train, y_train, x_val):\n",
    "    # model = SVR(verbose=True)\n",
    "    # model = MLPRegressor(hidden_layer_sizes=(512, 1024), verbose=True)\n",
    "    model = RandomForestRegressor(n_estimators=100, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_val)\n",
    "    return y_pred\n",
    "\n",
    "def transform_data(csv_dict, name):\n",
    "    return csv_dict\n",
    "\n",
    "df = train_per_dataset(\n",
    "    experiment_name=\"all data - x model\",\n",
    "    csv_dict=csv_dict, \n",
    "    names=names, \n",
    "    transform_data=transform_data, \n",
    "    fit_predict=fit_predict\n",
    "    )\n",
    "\n",
    "results = pd.concat([results, df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori Data - Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fhv',\n",
       "  Index(['PULocationID', 'DOLocationID', 'trip_miles', 'trip_time',\n",
       "         'base_passenger_fare', 'tolls', 'bcf', 'sales_tax',\n",
       "         'congestion_surcharge', 'tips', 'driver_pay', 'shared_request_flag',\n",
       "         'shared_match_flag', 'access_a_ride_flag', 'wav_request_flag',\n",
       "         'wav_match_flag', 'retail_price', 'temperature_2m (°C)',\n",
       "         'relative_humidity_2m (%)', 'dew_point_2m (°C)',\n",
       "         'apparent_temperature (°C)', 'precipitation (mm)', 'rain (mm)',\n",
       "         'snowfall (cm)', 'snow_depth (m)', 'surface_pressure (hPa)',\n",
       "         'cloud_cover (%)', 'wind_speed_10m (km/h)', 'is_day ()', 'PUBoroughID',\n",
       "         'DOBoroughID', 'wait_time', 'month', 'weekday', 'hour'],\n",
       "        dtype='object')),\n",
       " ('green',\n",
       "  Index(['VendorID', 'store_and_fwd_flag', 'RatecodeID', 'PULocationID',\n",
       "         'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount',\n",
       "         'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
       "         'improvement_surcharge', 'payment_type', 'trip_type',\n",
       "         'congestion_surcharge', 'retail_price', 'temperature_2m (°C)',\n",
       "         'relative_humidity_2m (%)', 'dew_point_2m (°C)',\n",
       "         'apparent_temperature (°C)', 'precipitation (mm)', 'rain (mm)',\n",
       "         'snowfall (cm)', 'snow_depth (m)', 'surface_pressure (hPa)',\n",
       "         'cloud_cover (%)', 'wind_speed_10m (km/h)', 'is_day ()', 'PUBoroughID',\n",
       "         'DOBoroughID', 'trip_time', 'month', 'weekday', 'hour'],\n",
       "        dtype='object')),\n",
       " ('yellow',\n",
       "  Index(['VendorID', 'passenger_count', 'trip_distance', 'RatecodeID',\n",
       "         'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type',\n",
       "         'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
       "         'improvement_surcharge', 'congestion_surcharge', 'retail_price',\n",
       "         'temperature_2m (°C)', 'relative_humidity_2m (%)', 'dew_point_2m (°C)',\n",
       "         'apparent_temperature (°C)', 'precipitation (mm)', 'rain (mm)',\n",
       "         'snowfall (cm)', 'snow_depth (m)', 'surface_pressure (hPa)',\n",
       "         'cloud_cover (%)', 'wind_speed_10m (km/h)', 'is_day ()', 'PUBoroughID',\n",
       "         'DOBoroughID', 'trip_time', 'month', 'weekday', 'hour'],\n",
       "        dtype='object'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, csv_dict[name][\"train\"].columns) for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ============================================================\n",
      "        Dataset: fhv\n",
      "\n",
      "        Train num: 953215\n",
      "        Val num: 476593\n",
      "        Train + Val num: 1429808\n",
      "\n",
      "        Train Mean tip: 0.762667058323673\n",
      "        Val Mean tip: 0.7605058823776264\n",
      "        Train + Val Mean tip: 0.7619466809529671\n",
      "        \n",
      "        Mean Squared Error: 4.8963749112554815\n",
      "        Mean Absolute Error: 1.244448960581793\n",
      "        ============================================================\n",
      "        \n",
      "\n",
      "        ============================================================\n",
      "        Dataset: green\n",
      "\n",
      "        Train num: 990533\n",
      "        Val num: 495264\n",
      "        Train + Val num: 1485797\n",
      "\n",
      "        Train Mean tip: 2.2083399139655118\n",
      "        Val Mean tip: 2.2135968089746076\n",
      "        Train + Val Mean tip: 2.210092206405047\n",
      "        \n",
      "        Mean Squared Error: 7.627464099730798\n",
      "        Mean Absolute Error: 1.5543121338027404\n",
      "        ============================================================\n",
      "        \n",
      "\n",
      "        ============================================================\n",
      "        Dataset: yellow\n",
      "\n",
      "        Train num: 994120\n",
      "        Val num: 497139\n",
      "        Train + Val num: 1491259\n",
      "\n",
      "        Train Mean tip: 3.308909900213255\n",
      "        Val Mean tip: 3.313971867023106\n",
      "        Train + Val Mean tip: 3.310597401256256\n",
      "        \n",
      "        Mean Squared Error: 7.705462275243002\n",
      "        Mean Absolute Error: 1.6583164715121628\n",
      "        ============================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_predict(x_train, y_train, x_val):\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_val)\n",
    "    return y_pred\n",
    "\n",
    "def transform_data(csv_dict, name):\n",
    "    \n",
    "    \n",
    "    if name == 'fhv':\n",
    "        labels_drop = [\n",
    "            # 'PULocationID', \n",
    "            # 'DOLocationID', \n",
    "            # 'trip_miles', \n",
    "            'trip_time',\n",
    "            'base_passenger_fare', \n",
    "            'tolls', \n",
    "            'bcf', \n",
    "            'sales_tax',\n",
    "            'congestion_surcharge', \n",
    "            # 'tips', \n",
    "            'driver_pay', \n",
    "            # 'shared_request_flag',\n",
    "            # 'shared_match_flag', \n",
    "            # 'access_a_ride_flag', \n",
    "            'wav_request_flag',\n",
    "            'wav_match_flag', \n",
    "            # 'retail_price', \n",
    "            # 'temperature_2m (°C)',\n",
    "            # 'relative_humidity_2m (%)', \n",
    "            # 'dew_point_2m (°C)',\n",
    "            # 'apparent_temperature (°C)', \n",
    "            # 'precipitation (mm)', \n",
    "            # 'rain (mm)',\n",
    "            # 'snowfall (cm)', \n",
    "            # 'snow_depth (m)', \n",
    "            # 'surface_pressure (hPa)',\n",
    "            # 'cloud_cover (%)', \n",
    "            # 'wind_speed_10m (km/h)', \n",
    "            # 'is_day ()', \n",
    "            # 'PUBoroughID',\n",
    "            # 'DOBoroughID', \n",
    "            # 'wait_time', \n",
    "            # 'month', \n",
    "            # 'weekday', \n",
    "            # 'hour'\n",
    "            ]\n",
    "    \n",
    "    if name == 'green':\n",
    "        labels_drop = [\n",
    "            # 'VendorID', \n",
    "            # 'store_and_fwd_flag', \n",
    "            'RatecodeID', \n",
    "            # 'PULocationID',\n",
    "            # 'DOLocationID', \n",
    "            # 'passenger_count', \n",
    "            # 'trip_distance', \n",
    "            'fare_amount',\n",
    "            'extra', \n",
    "            'mta_tax', \n",
    "            # 'tip_amount', \n",
    "            'tolls_amount',\n",
    "            'improvement_surcharge', \n",
    "            'payment_type', \n",
    "            # 'trip_type',\n",
    "            'congestion_surcharge', \n",
    "            # 'retail_price', \n",
    "            # 'temperature_2m (°C)',\n",
    "            # 'relative_humidity_2m (%)', \n",
    "            # 'dew_point_2m (°C)',\n",
    "            # 'apparent_temperature (°C)', \n",
    "            # 'precipitation (mm)', \n",
    "            # 'rain (mm)',\n",
    "            # 'snowfall (cm)', \n",
    "            # 'snow_depth (m)', \n",
    "            # 'surface_pressure (hPa)',\n",
    "            # 'cloud_cover (%)', \n",
    "            # 'wind_speed_10m (km/h)', \n",
    "            # 'is_day ()', \n",
    "            # 'PUBoroughID',\n",
    "            # 'DOBoroughID', \n",
    "            # 'trip_time', \n",
    "            # 'month', \n",
    "            # 'weekday', \n",
    "            # 'hour'\n",
    "            ]\n",
    "           \n",
    "    if name == 'yellow':\n",
    "        labels_drop = [\n",
    "            # 'VendorID', \n",
    "            # 'passenger_count', \n",
    "            # 'trip_distance', \n",
    "            'RatecodeID',\n",
    "            # 'store_and_fwd_flag', \n",
    "            # 'PULocationID', \n",
    "            # 'DOLocationID', \n",
    "            # 'payment_type',\n",
    "            'fare_amount', \n",
    "            'extra', \n",
    "            'mta_tax', \n",
    "            # 'tip_amount', \n",
    "            'tolls_amount',\n",
    "            'improvement_surcharge', \n",
    "            'congestion_surcharge', \n",
    "            # 'retail_price',\n",
    "            # 'temperature_2m (°C)', \n",
    "            # 'relative_humidity_2m (%)', \n",
    "            # 'dew_point_2m (°C)',\n",
    "            # 'apparent_temperature (°C)', \n",
    "            # 'precipitation (mm)', \n",
    "            # 'rain (mm)',\n",
    "            # 'snowfall (cm)', \n",
    "            # 'snow_depth (m)', \n",
    "            # 'surface_pressure (hPa)',\n",
    "            # 'cloud_cover (%)', \n",
    "            # 'wind_speed_10m (km/h)', \n",
    "            # 'is_day ()', \n",
    "            # 'PUBoroughID',\n",
    "            # 'DOBoroughID', \n",
    "            # 'trip_time', \n",
    "            # 'month',\n",
    "            # 'weekday', \n",
    "            # 'hour'\n",
    "            ]\n",
    "\n",
    "    \n",
    "    csv_dict['train'] = csv_dict[\"train\"].drop(columns=labels_drop)\n",
    "    csv_dict['valid'] = csv_dict[\"valid\"].drop(columns=labels_drop)\n",
    "     \n",
    "    return csv_dict\n",
    "\n",
    "df = train_per_dataset(\n",
    "    experiment_name=\"apriori data - regression model\",\n",
    "    csv_dict=csv_dict, \n",
    "    names=names, \n",
    "    transform_data=transform_data, \n",
    "    fit_predict=fit_predict\n",
    "    )\n",
    "\n",
    "results = pd.concat([results, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Additional Data - Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ============================================================\n",
      "        Dataset: fhv\n",
      "\n",
      "        Train num: 953215\n",
      "        Val num: 476593\n",
      "        Train + Val num: 1429808\n",
      "\n",
      "        Train Mean tip: 0.762667058323673\n",
      "        Val Mean tip: 0.7605058823776264\n",
      "        Train + Val Mean tip: 0.7619466809529671\n",
      "        \n",
      "        Mean Squared Error: 4.637112855270725\n",
      "        Mean Absolute Error: 1.2075998834158606\n",
      "        ============================================================\n",
      "        \n",
      "\n",
      "        ============================================================\n",
      "        Dataset: green\n",
      "\n",
      "        Train num: 990533\n",
      "        Val num: 495264\n",
      "        Train + Val num: 1485797\n",
      "\n",
      "        Train Mean tip: 2.2083399139655118\n",
      "        Val Mean tip: 2.2135968089746076\n",
      "        Train + Val Mean tip: 2.210092206405047\n",
      "        \n",
      "        Mean Squared Error: 6.70013156118884\n",
      "        Mean Absolute Error: 1.4006858458696765\n",
      "        ============================================================\n",
      "        \n",
      "\n",
      "        ============================================================\n",
      "        Dataset: yellow\n",
      "\n",
      "        Train num: 994120\n",
      "        Val num: 497139\n",
      "        Train + Val num: 1491259\n",
      "\n",
      "        Train Mean tip: 3.308909900213255\n",
      "        Val Mean tip: 3.313971867023106\n",
      "        Train + Val Mean tip: 3.310597401256256\n",
      "        \n",
      "        Mean Squared Error: 3.9560576062100137\n",
      "        Mean Absolute Error: 0.9591666760952402\n",
      "        ============================================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_predict(x_train, y_train, x_val):\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_val)\n",
    "    return y_pred\n",
    "\n",
    "def transform_data(csv_dict, name):\n",
    "    \n",
    "    \n",
    "    if name == 'fhv':\n",
    "        labels_drop = [\n",
    "            # 'PULocationID', \n",
    "            # 'DOLocationID', \n",
    "            # 'trip_miles', \n",
    "            # 'trip_time',\n",
    "            # 'base_passenger_fare', \n",
    "            # 'tolls', \n",
    "            # 'bcf', \n",
    "            # 'sales_tax',\n",
    "            # 'congestion_surcharge', \n",
    "            # 'tips', \n",
    "            # 'driver_pay', \n",
    "            # 'shared_request_flag',\n",
    "            # 'shared_match_flag', \n",
    "            # 'access_a_ride_flag', \n",
    "            # 'wav_request_flag',\n",
    "            # 'wav_match_flag', \n",
    "            'retail_price', \n",
    "            'temperature_2m (°C)',\n",
    "            'relative_humidity_2m (%)', \n",
    "            'dew_point_2m (°C)',\n",
    "            'apparent_temperature (°C)', \n",
    "            'precipitation (mm)', \n",
    "            'rain (mm)',\n",
    "            'snowfall (cm)', \n",
    "            'snow_depth (m)', \n",
    "            'surface_pressure (hPa)',\n",
    "            'cloud_cover (%)', \n",
    "            'wind_speed_10m (km/h)', \n",
    "            # 'is_day ()', \n",
    "            # 'PUBoroughID',\n",
    "            # 'DOBoroughID', \n",
    "            # 'wait_time', \n",
    "            # 'month', \n",
    "            # 'weekday', \n",
    "            # 'hour'\n",
    "            ]\n",
    "    \n",
    "    if name == 'green':\n",
    "        labels_drop = [\n",
    "            # 'VendorID', \n",
    "            # 'store_and_fwd_flag', \n",
    "            # 'RatecodeID', \n",
    "            # 'PULocationID',\n",
    "            # 'DOLocationID', \n",
    "            # 'passenger_count', \n",
    "            # 'trip_distance', \n",
    "            # 'fare_amount',\n",
    "            # 'extra', \n",
    "            # 'mta_tax', \n",
    "            # 'tip_amount', \n",
    "            # 'tolls_amount',\n",
    "            # 'improvement_surcharge', \n",
    "            # 'payment_type', \n",
    "            # 'trip_type',\n",
    "            # 'congestion_surcharge', \n",
    "            'retail_price', \n",
    "            'temperature_2m (°C)',\n",
    "            'relative_humidity_2m (%)', \n",
    "            'dew_point_2m (°C)',\n",
    "            'apparent_temperature (°C)', \n",
    "            'precipitation (mm)', \n",
    "            'rain (mm)',\n",
    "            'snowfall (cm)', \n",
    "            'snow_depth (m)', \n",
    "            'surface_pressure (hPa)',\n",
    "            'cloud_cover (%)', \n",
    "            'wind_speed_10m (km/h)', \n",
    "            # 'is_day ()', \n",
    "            # 'PUBoroughID',\n",
    "            # 'DOBoroughID', \n",
    "            # 'trip_time', \n",
    "            # 'month', \n",
    "            # 'weekday', \n",
    "            # 'hour'\n",
    "            ]\n",
    "           \n",
    "    if name == 'yellow':\n",
    "        labels_drop = [\n",
    "            # 'VendorID', \n",
    "            # 'passenger_count', \n",
    "            # 'trip_distance', \n",
    "            # 'RatecodeID',\n",
    "            # 'store_and_fwd_flag', \n",
    "            # 'PULocationID', \n",
    "            # 'DOLocationID', \n",
    "            # 'payment_type',\n",
    "            # 'fare_amount', \n",
    "            # 'extra', \n",
    "            # 'mta_tax', \n",
    "            # 'tip_amount', \n",
    "            # 'tolls_amount',\n",
    "            # 'improvement_surcharge', \n",
    "            # 'congestion_surcharge', \n",
    "            'retail_price',\n",
    "            'temperature_2m (°C)', \n",
    "            'relative_humidity_2m (%)', \n",
    "            'dew_point_2m (°C)',\n",
    "            'apparent_temperature (°C)', \n",
    "            'precipitation (mm)', \n",
    "            'rain (mm)',\n",
    "            'snowfall (cm)', \n",
    "            'snow_depth (m)', \n",
    "            'surface_pressure (hPa)',\n",
    "            'cloud_cover (%)', \n",
    "            'wind_speed_10m (km/h)', \n",
    "            # 'is_day ()', \n",
    "            # 'PUBoroughID',\n",
    "            # 'DOBoroughID', \n",
    "            # 'trip_time', \n",
    "            # 'month',\n",
    "            # 'weekday', \n",
    "            # 'hour'\n",
    "            ]\n",
    "\n",
    "    \n",
    "    csv_dict['train'] = csv_dict[\"train\"].drop(columns=labels_drop)\n",
    "    csv_dict['valid'] = csv_dict[\"valid\"].drop(columns=labels_drop)\n",
    "     \n",
    "    return csv_dict\n",
    "\n",
    "df = train_per_dataset(\n",
    "    experiment_name=\"no additional data - regression model\",\n",
    "    csv_dict=csv_dict, \n",
    "    names=names, \n",
    "    transform_data=transform_data, \n",
    "    fit_predict=fit_predict\n",
    "    )\n",
    "\n",
    "results = pd.concat([results, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>name</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all data - regression model</td>\n",
       "      <td>fhv</td>\n",
       "      <td>4.634459</td>\n",
       "      <td>1.207607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all data - regression model</td>\n",
       "      <td>green</td>\n",
       "      <td>6.683244</td>\n",
       "      <td>1.398348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all data - regression model</td>\n",
       "      <td>yellow</td>\n",
       "      <td>3.954368</td>\n",
       "      <td>0.959758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apriori data - regression model</td>\n",
       "      <td>fhv</td>\n",
       "      <td>4.896375</td>\n",
       "      <td>1.244449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apriori data - regression model</td>\n",
       "      <td>green</td>\n",
       "      <td>7.627464</td>\n",
       "      <td>1.554312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apriori data - regression model</td>\n",
       "      <td>yellow</td>\n",
       "      <td>7.705462</td>\n",
       "      <td>1.658316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no additional data - regression model</td>\n",
       "      <td>fhv</td>\n",
       "      <td>4.637113</td>\n",
       "      <td>1.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no additional data - regression model</td>\n",
       "      <td>green</td>\n",
       "      <td>6.700132</td>\n",
       "      <td>1.400686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no additional data - regression model</td>\n",
       "      <td>yellow</td>\n",
       "      <td>3.956058</td>\n",
       "      <td>0.959167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         experiment_name    name       mse       mae\n",
       "0            all data - regression model     fhv  4.634459  1.207607\n",
       "0            all data - regression model   green  6.683244  1.398348\n",
       "0            all data - regression model  yellow  3.954368  0.959758\n",
       "0        apriori data - regression model     fhv  4.896375  1.244449\n",
       "0        apriori data - regression model   green  7.627464  1.554312\n",
       "0        apriori data - regression model  yellow  7.705462  1.658316\n",
       "0  no additional data - regression model     fhv  4.637113  1.207600\n",
       "0  no additional data - regression model   green  6.700132  1.400686\n",
       "0  no additional data - regression model  yellow  3.956058  0.959167"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>name</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no additional data - regression model</td>\n",
       "      <td>yellow</td>\n",
       "      <td>3.956058</td>\n",
       "      <td>0.959167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all data - regression model</td>\n",
       "      <td>yellow</td>\n",
       "      <td>3.954368</td>\n",
       "      <td>0.959758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no additional data - regression model</td>\n",
       "      <td>fhv</td>\n",
       "      <td>4.637113</td>\n",
       "      <td>1.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all data - regression model</td>\n",
       "      <td>fhv</td>\n",
       "      <td>4.634459</td>\n",
       "      <td>1.207607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apriori data - regression model</td>\n",
       "      <td>fhv</td>\n",
       "      <td>4.896375</td>\n",
       "      <td>1.244449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all data - regression model</td>\n",
       "      <td>green</td>\n",
       "      <td>6.683244</td>\n",
       "      <td>1.398348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no additional data - regression model</td>\n",
       "      <td>green</td>\n",
       "      <td>6.700132</td>\n",
       "      <td>1.400686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apriori data - regression model</td>\n",
       "      <td>green</td>\n",
       "      <td>7.627464</td>\n",
       "      <td>1.554312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apriori data - regression model</td>\n",
       "      <td>yellow</td>\n",
       "      <td>7.705462</td>\n",
       "      <td>1.658316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         experiment_name    name       mse       mae\n",
       "0  no additional data - regression model  yellow  3.956058  0.959167\n",
       "0            all data - regression model  yellow  3.954368  0.959758\n",
       "0  no additional data - regression model     fhv  4.637113  1.207600\n",
       "0            all data - regression model     fhv  4.634459  1.207607\n",
       "0        apriori data - regression model     fhv  4.896375  1.244449\n",
       "0            all data - regression model   green  6.683244  1.398348\n",
       "0  no additional data - regression model   green  6.700132  1.400686\n",
       "0        apriori data - regression model   green  7.627464  1.554312\n",
       "0        apriori data - regression model  yellow  7.705462  1.658316"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=\"mae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wszystki dane\n",
    "- dane które są znane przed wyjazdem taksówkarza\n",
    "- bez danych paliwowych i pogodowych, żeby zobaczyć czy coś daje"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
